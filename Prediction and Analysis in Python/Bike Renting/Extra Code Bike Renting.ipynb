{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_tree = 0\n",
    "for tree_in_forest in rfModel.estimators_:\n",
    "    if (i_tree <1):        \n",
    "       export_graphviz(tree_in_forest,\n",
    "                feature_names= x_train.columns,\n",
    "                filled=True,\n",
    "                rounded=True)\n",
    "    i_tree = i_tree + 1\n",
    "    os.system('dot -Tpng tree.dot -o tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets check what was the majorty reason for the absent hours\n",
    "main_col = 'Reason_for_absence'\n",
    "other_col = ['Disciplinary_failure','Social_drinker', 'Social_smoker']\n",
    "corr_mat1 = []\n",
    "for col in other_col[0:]:\n",
    "    confusion_matrix = pd.crosstab(complete_data[main_col], complete_data[col])\n",
    "    corr_mat1.append(confusion_matrix)\n",
    "    \n",
    "def highlight_min(x):\n",
    "    is_max = x  == x.max()\n",
    "    return['background: yellow' if v else '' for v in is_max]\n",
    "\n",
    "out = pd.concat(corr_mat1, axis = 1, keys = other_col[0:])\n",
    "out = out.style.apply(highlight_min, axis = 0)\n",
    "out\n",
    "#out.to_html('out.html')\n",
    "\n",
    "#Cross tab is used when the categories for columns which we are comparing are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize and denormalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#scaled = scaler.fit_transform(df)\n",
    "unscaled = scaler.inverse_transform(daily_data.humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Modelling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, yLabelsLog)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_cv)\n",
    "# evaluate predictions\n",
    "print (\"RMSLE Value Decision tree\", rmsle(np.exp(yLabelsLogtest),np.exp(y_pred),False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making  linear regression object\n",
    "lr = LinearRegression()\n",
    "#Training the model\n",
    "fit = lr.fit(x_train, y_train)\n",
    "\n",
    "b_0   = fit.intercept_\n",
    "coeff = fit.coef_\n",
    "print('Intercept:  %.4f' % b_0)\n",
    "print('Month Coefficient value: ' % coeff)\n",
    "\n",
    "\n",
    "#Making predictions\n",
    "pred = lr.predict(x_cv)\n",
    "\n",
    "#Plotting the prediction with the original values plot\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "\n",
    "\n",
    "\n",
    "#Making predictions\n",
    "pred = lr.predict(x_cv)\n",
    "\n",
    "#Plotting the prediction with the original values plot\n",
    "mse = np.mean((pred - y_cv)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rfModel = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "yLabelsLogtest = np.log1p(ytestLabels)\n",
    "\n",
    "rfModel.fit(x_train,yLabelsLog)\n",
    "\n",
    "preds = rfModel.predict(X= x_cv)\n",
    "\n",
    "print (\"RMSLE Value For Random Forest: \", rmsle(np.exp(yLabelsLogtest),np.exp(preds),False))\n",
    "\n",
    "\n",
    "score = rfModel.score(x_train, yLabelsLog)\n",
    "print ('Random Forest R square: %.4f' % score)\n",
    "\n",
    "\n",
    "\n",
    "tree_small= rfModel.estimators_[5]\n",
    "export_graphviz(tree_small,\n",
    "                feature_names= x_train.columns,\n",
    "                filled=True,\n",
    "                rounded=True)\n",
    "os.system('dot -Tpng tree.dot -o tree.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "importances = list(rfModel.feature_importances_)\n",
    "feature_list = x_train.columns\n",
    "# Set the style\n",
    "#plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.expm1(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XG boost\n",
    "\n",
    "xgr=xg.XGBRegressor(max_depth=8,min_child_weight=6,gamma=0.4)\n",
    "xgr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e4de8b98eef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Making  linear regression object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#Training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "#Linear REgression\n",
    "\n",
    "#Making  linear regression object\n",
    "lr = LinearRegression()\n",
    "#Training the model\n",
    "fit = lr.fit(x_train, y_train)\n",
    "\n",
    "b_0   = fit.intercept_\n",
    "coeff = fit.coef_\n",
    "print('Intercept:  %.4f' % b_0)\n",
    "print('Month Coefficient value: ' % coeff)\n",
    "\n",
    "#Making predictions\n",
    "pred = lr.predict(x_cv)\n",
    "\n",
    "#Plotting the prediction with the original values plot\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "\n",
    "\n",
    "lin_mse = mean_squared_error(pred, y_cv)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print('RMSE: %.4f' % lin_rmse)\n",
    "\n",
    "\n",
    "#Linear Regression with log transformation\n",
    "\n",
    "def rmsle(y, y_,convertExp=True):\n",
    "    if convertExp:\n",
    "        y = np.exp(y),\n",
    "        y_ = np.exp(y_)\n",
    "    log1 = np.array([np.log(v + 1) for v in y])\n",
    "    log2 = np.array([np.log(v + 1) for v in y_])\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return np.sqrt(np.mean(calc))\n",
    "\n",
    "\n",
    "# Initialize logistic regression model\n",
    "lModel = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "yLabelsLogtest = np.log1p(ytestLabels)\n",
    "\n",
    "lModel.fit(X = x_train,y = yLabelsLog)\n",
    "\n",
    "# Make predictions\n",
    "preds = lModel.predict(X= x_cv)\n",
    "print (\"RMSLE Value For Linear Regression: \",rmsle(np.exp(yLabelsLogtest),np.exp(preds),False))\n",
    "\n",
    "\n",
    "score = lModel.score(x_train, yLabelsLog)\n",
    "print ('Linear Regression without trend R square: %.4f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dc179b31115f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m dtmodel = DecisionTreeRegressor(max_depth=4,\n\u001b[0m\u001b[0;32m      5\u001b[0m                            \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                            max_leaf_nodes=10)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "#Decsion Tree\n",
    "\n",
    "\n",
    "dtmodel = DecisionTreeRegressor(max_depth=4,\n",
    "                           min_samples_split=5,\n",
    "                           max_leaf_nodes=10)\n",
    "\n",
    "#yLabelsLog = np.log1p(yLabels)\n",
    "#yLabelsLogtest = np.log1p(ytestLabels)\n",
    "\n",
    "dtmodel.fit(x_train, y_train)\n",
    "\n",
    "predictions = dtmodel.predict(x_cv)\n",
    "dtmodel\n",
    "#print (\"RMSLE Value Decision tree\", rmsle(np.exp(yLabelsLogtest),np.exp(preds),False))\n",
    "\n",
    "\n",
    "#R -square\n",
    "score = dtmodel.score(x_train, y_train)\n",
    "print ('Decsion Tree R square: %.4f' % score)\n",
    "\n",
    "\n",
    "#RMSE\n",
    "mse = mean_squared_error(predictions, y_cv)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Decision tree RMSE: %.4f' % rmse)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"criterion\": [\"mse\", \"mae\"],\n",
    "              \"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100],\n",
    "              }\n",
    "\n",
    "grid_cv_dtm = GridSearchCV(dtmodel, param_grid, cv=5)\n",
    "\n",
    "grid_cv_dtm.fit(x_train, y_train)\n",
    "\n",
    "print(\"R-Squared::{}\".format(grid_cv_dtm.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtm.best_params_))\n",
    "\n",
    "importances = list(dtmodel.feature_importances_)\n",
    "feature_list = x_train.columns\n",
    "# Set the style\n",
    "#plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "\n",
    "#Exporting the tree\n",
    "export_graphviz(DTModel,\n",
    "                feature_names= x_train.columns,\n",
    "                filled=True,\n",
    "                rounded=True, special_characters=True)\n",
    "os.system('dot -Tpng tree.dot -o tree.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfModel = RandomForestRegressor(n_estimators=100)\n",
    "yLabelsLog = np.log1p(yLabels)\n",
    "rfModel.fit(x_train, y_train)\n",
    "preds = rfModel.predict(x_cv)\n",
    "\n",
    "\n",
    "importances = list(rfModel.feature_importances_)\n",
    "feature_list = x_train.columns\n",
    "# Set the style\n",
    "#plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');\n",
    "\n",
    "\n",
    "#Exporting the tree\n",
    "export_graphviz(DTModel,\n",
    "                feature_names= x_train.columns,\n",
    "                filled=True,\n",
    "                rounded=True, special_characters=True)\n",
    "os.system('dot -Tpng tree.dot -o tree.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_):\n",
    "    log1 = np.array([np.log(v) for v in y])\n",
    "    log2 = np.array([np.log(v) for v in y_])\n",
    "    calc = (log1 - log2) ** 2\n",
    "    return np.sqrt(np.mean(calc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_df=pd.get_dummies(daily_data['weather_type'],prefix='w',drop_first=True)\n",
    "year_df=pd.get_dummies(daily_data['year'],prefix='y',drop_first=True)\n",
    "month_df=pd.get_dummies(daily_data['month'],prefix='m',drop_first=True)\n",
    "working_df=pd.get_dummies(daily_data['workingday'],prefix='work',drop_first=True)\n",
    "season_df=pd.get_dummies(daily_data['season'],prefix='s',drop_first=True)\n",
    "week_df=pd.get_dummies(daily_data['weekday'],prefix='week',drop_first=True)\n",
    "                     \n",
    "\n",
    "\n",
    "daily_data=daily_data.join(weather_df)\n",
    "daily_data=daily_data.join(year_df)\n",
    "daily_data=daily_data.join(month_df)                     \n",
    "daily_data=daily_data.join(working_df)\n",
    "daily_data=daily_data.join(season_df)\n",
    "daily_data=daily_data.join(week_df)\n",
    "\n",
    "\n",
    "                     \n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XG boost\n",
    "import xgboost as xg\n",
    "xgr=xg.XGBRegressor(max_depth=8,min_child_weight=6,gamma=0.4)\n",
    "xgr.fit(x_train, yLabels)\n",
    "\n",
    "preds = xgr.predict(x_cv)\n",
    "\n",
    "#RMSE\n",
    "mse = mean_squared_error(preds, ytestLabels)\n",
    "rmse = np.sqrt(mse)\n",
    "print('XG Boost RMSE: %.4f' % rmse)\n",
    "\n",
    "#R -square\n",
    "score = xgr.score(x_train, yLabels)\n",
    "print ('XG Boost R square: %.4f' % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
